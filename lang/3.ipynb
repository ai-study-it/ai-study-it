{"cells":[{"cell_type":"markdown","metadata":{"id":"5tys7YJTKEFG"},"source":["<h2> cv </h2>\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVtQIv60KEFG"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","# Parameter\n","IMG_SIZE = 150\n","BATCH_SIZE = 32\n","EPOCHS = 15\n","BASE_DIR = \"03_clean_desk\"\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    os.path.join(BASE_DIR, \"train\"),\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='binary'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZOtv22JKEFG"},"outputs":[],"source":["# Model Definition\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE,3)),\n","    MaxPooling2D(2,2),\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Conv2D(128, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Conv2D(128, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(\n","   train_generator,\n","   epochs=EPOCHS,\n","   steps_per_epoch = train_generator.samples // BATCH_SIZE\n",")\n","\n","model.save(\".h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_-14uwUKEFG"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import os\n","\n","test_dir = \"03_clean_desk/test\"\n","image_paths = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.lower().endswith(('.png','.jpg','.jpeg','.gif','.bmp'))]\n","\n","IMG_SIZE = 150\n","\n","def load_and_preprocess_image(img_path):\n","    img = tf.io.read_file(img_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n","    img /= 255.0\n","    return img\n","\n","# Dataset 생성\n","test_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n","test_dataset = test_dataset.map(load_and_preprocess_image).batch(BATCH_SIZE)\n","\n","model = tf.keras.models.load_model(\".h5\")\n","\n","predictions = model.predict(test_dataset)\n","predicted_labels = [\"clean\" if pred <0.5 else \"not_clean\" for pred in predictions.squeeze()]\n","\n","result_df = pd.DataFrame({\n","    'file name' : [os.path.basename(fname) for fname in image_paths],\n","    'label' : predicted_labels\n","})\n","\n","\n","result_df.to_csv(\".csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqRTTgDyKEFH"},"outputs":[],"source":["import pandas as pd\n","\n","result_path = \".csv\"\n","loaded_df = pd.read_csv(result_path)\n","\n","print(loaded_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5xvvM9slKEFH"},"outputs":[],"source":["import os\n","\n","test_dir = \"03_clean_desk/test\"\n","file_list = os.listdir(test_dir)\n","\n","image_files = [f for f in file_list if f.lower().endswith(('.png', '.jpg', '.gif', '.bmp'))]\n","\n","print(f\"Number of image files in '{test_dir}' : {len(image_files)}\")"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}